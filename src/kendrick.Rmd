---
title: "Kendrick LamaR"
output: github_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggrepel)
library(ggthemes)
library(grid)
library(gridExtra)
library(httr)
library(knitr)
library(lubridate)
library(magick)
library(png)
library(RColorBrewer)
library(reshape2)
library(rvest)
library(scales)
library(stringr)
library(tidytext)
library(tidyverse)
library(wordcloud)
```

Millions of people are listening to Kendrick Lamar's music, and many are analysing his lyrics too. On [Genius](https://genius.com/artists/Kendrick-lamar), a lyric annotation website, the songs on Kendrick's studio albums have over 70 million pageviews. Many of these songs have dozens of annotations, which are often refined by hundreds of contributors, including the Pullitzer-prize winning author [Michael Chabon](http://pitchfork.com/news/58421-kendrick-lamars-the-blacker-the-berry-gets-annotated-for-genius-by-pulitzer-winning-author-michael-chabon/).

But not too many people are analysing Kendrick's music with hard data, so I decided to give it a shot. A few months ago I read a fantastic data science blog post by RCharlie which tried to pin down [the most depressing Radiohead song](http://rcharlie.com/2017-02-16-fitteR-happieR/), using data from Spotify and Genius. I modified RCharlie's code to get the data on Kendrick's music. If you're interested, my script for scraping the data is [here](https://github.com/laingdk/kendrick/blob/master/src/scrape_kendrick.R), and the data is [here](https://github.com/laingdk/kendrick/blob/master/data/scraped_kendrick_data.csv).

I've included all my code in the post, but if you're not into that, you should be able follow along with the writing and the visualizations alone. If you want, you can skip ahead to the really cool part.

Let's get started! I began by loading the data and fixing some factor levels.

```{r load, message = FALSE, warning = FALSE}
# Read in the data.
kendrick <- read.csv("../data/kendrick_data.csv")

# Fix the factor levels for the albums.
kendrick$album_name <- factor(kendrick$album_name, levels = c("Overly Dedicated", "Section.80", "good kid, m.A.A.d city", "To Pimp A Butterfly", "untitled unmastered.", "DAMN."))

# Remove Overly Dedicated (because it's technically a mixtape, not a studio album).
kendrick <- kendrick %>% filter(album_name != "Overly Dedicated")

# Fix the factor levels for the tracks.
kendrick$track_name <- factor(kendrick$track_name, levels = as.character(kendrick$track_name))
```

The first thing I wanted to know was which of Kendrick's songs are the most analysed on Genius. One measure of this is the number of annotations for a given song. The only problem is that some songs have fewer lyrics than others, and no lyric can have more than one annotation. So I used the number of annotations per word.

```{r viz, message=FALSE, warning=FALSE}
# Get the number of annotations per word.
kendrick <- kendrick %>% mutate(ann_per_word = annotations/song_word_count)

# Plot the annotations per word.
annotation_plot <- ggplot(kendrick) +
        geom_col(aes(x = track_name,
                     y = ann_per_word,
                     fill = album_name), 
                 alpha = 0.8,
                 show.legend = FALSE) +
        facet_grid(~album_name, scales = "free", space = "free") +
        theme_few(base_family = 'GillSans') +
        theme(axis.text.x=element_text(size = 4, angle = 90, hjust = 1, vjust = 0.2),
              axis.text.y=element_text(size = 5, angle = 90),
              axis.title.x=element_text(size = 9, angle = 180),
              axis.title.y=element_text(size = 9, angle = 90),
              strip.text = element_text(size = 7, angle = 90, vjust = 0)) +
        scale_fill_manual(values = c("purple", "darkblue", "darkgrey", "darkgreen", "red")) +
        ylab("Annotations Per Word across Kendrick Lamar's Discography") +
        xlab("")

# Since facet_wrap doesn't play nicely with coord_flip, I had to do a bit of acrobatics to rotate the plot properly.
ggsave("../results/annotation_plot.png", width = 4, height = 5)  ## Save it.
annotation_plot <- image_read('../results/annotation_plot.png')  ## Read it back in.
annotation_plot <- image_rotate(annotation_plot, 90)  ## Rotate it.
image_write(annotation_plot, path = "../results/annotation_plot.png", format = "png")  ## Save it again.
```

![](../results/annotation_plot.png)

The data have offered up [For Free? - Interlude](https://genius.com/5047115) as the most analysed Kendrick Lamar song:

<iframe width="560" height="315" src="https://www.youtube.com/embed/_ZTYgq4EoRo" frameborder="0" allowfullscreen></iframe>

I'm pretty satisfied with this answer. The song is dizzyingly complex, both lyrically and musically, and it's chock-full of symbolism, history, and wordplay.

Runners-up are [Rigamortis](https://genius.com/Kendrick-lamar-rigamortus-lyrics) and [HiiiPower](https://genius.com/Kendrick-lamar-hiiipower-lyrics):

<iframe width="280" height="157" src="https://www.youtube.com/embed/sBvngg87998" frameborder="0" allowfullscreen></iframe><iframe width="280" height="157" src="https://www.youtube.com/embed/RT2ZCdPVLAs" frameborder="0" allowfullscreen></iframe>

I wanted to know how musical and lyrical sentiment vary within and between Kendrick's albums. The first part is easy: Spotify's API provides a variable called "valence", which is defined as follows:

> A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).

Below is a plot of the valence of Kendrick's music across his studio albums.

```{r valence_plot}
# See how the sentiment changes across the albums.
valence_plot <- ggplot(kendrick, aes(x = track_name, y = (2*valence)-1, color = (2*valence)-1)) +
        geom_hline(aes(yintercept=1, color=1), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=0.5, color=0.5), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=0, color=0), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=-0.5, color=-0.5), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=-1, color=-1), linetype="dashed", show.legend = FALSE) +
        geom_point(aes(x = track_name, y = (2*valence)-1), size=0.1, show.legend = FALSE) +
        geom_smooth(aes(x = as.numeric(track_number), color=..y..), size = 1, show.legend = FALSE, se = FALSE, span = 0.3) +
        geom_smooth(aes(x = as.numeric(track_number)), color="black", size = 0.2, show.legend = FALSE, alpha = 0.9, se = FALSE, span = 0.3) +
        facet_grid(~album_name, scales = "free", space = "free") +
        scale_color_distiller(type = "div", palette = "RdYlGn", direction = 1, values = c(0,0.5,1)) +
        theme_few(base_family = 'GillSans') +
        theme(axis.text.x=element_text(size = 4, angle = 90, hjust = 1, vjust = 0.2),
              axis.text.y=element_text(size = 5, angle = 90, hjust = 0.5),
              axis.title.x=element_text(size = 9, angle = 180),
              axis.title.y=element_text(size = 9, angle = 90),
              strip.text = element_text(size = 7, angle = 90, vjust = 0)) +
        xlab("") +
        ylab("Musical sentiment in Kendrick Lamar's albums") +
        scale_y_continuous(limits = c(-1,1),
                           labels = c("very negative", 
                                      "negative", 
                                      "neutral", 
                                      "positive", 
                                      "very positive"))

# Save and rotate.
ggsave("../results/valence_plot.png", width = 4, height = 5)
valence_plot <- image_read('../results/valence_plot.png')
valence_plot <- image_rotate(valence_plot, 90)
image_write(valence_plot, path = "../results/valence_plot.png", format = "png")
```

![](../results/valence_plot.png)

Kendrick fans will recognize many of these scores as vaguely correct, but several of them are not. For example, the highest-scoring song was [Blow My High (Members Only)](https://genius.com/Kendrick-lamar-blow-my-high-members-only-lyrics):

<iframe width="560" height="315" src="https://www.youtube.com/embed/n4bm7hqu_GE" frameborder="0" allowfullscreen></iframe>

While it's by no means a sad or even angry song, it doesn't reach emotional highs anywhere near what you'd expect from the Most Positive Song in Kendrick's career. So, Spotify's valence variable is incomplete as a measure of overall sentiment.

I was interested in the sentiment in the lyrics alone, but this time I had to compute it myself. I joined the lyrics with the Bing lexicon — a list of words which are labelled by humans as positive or negative — and subtracted the negative words from the positive ones to get a general measure of lyrical sentiment. In each song, I normalized the sentiment by dividing by the total number of words that were present in both the song and the Bing lexicon. Below I plot the lyrical sentiment across albums.

```{r sentiment, message = FALSE, warning = FALSE}
# Change the text from factor to character.
kendrick$lyrics <- as.character(kendrick$lyrics)

# Get one word per row.
tidy_kendrick <- kendrick %>% unnest_tokens(word, lyrics)

# Remove stop words. (These are words like "the" and "a", which only carry syntactic meaning.)
cleaned_kendrick <- tidy_kendrick %>%
        anti_join(stop_words)

# Get the sentiment of words in the Bing lexicon.
bing <- get_sentiments("bing")

# Get the sentiment across the tracks.
kendrick_sentiment <- cleaned_kendrick %>%
        inner_join(bing) %>%
        count(track_name, sentiment) %>%
        spread(sentiment, n, fill = 0) %>%
        mutate(sentiment = (positive - negative)/(positive + negative))

# Join the sentiment with the original dataset.
kendrick <- inner_join(kendrick, kendrick_sentiment)

# See how the sentiment changes across the albums.
lyric_sent_plot <- ggplot(kendrick, aes(x = track_name, y = sentiment, color = sentiment)) +
        geom_hline(aes(yintercept=1, color=1), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=0.5, color=0.5), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=0, color=0), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=-0.5, color=-0.5), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=-1, color=-1), linetype="dashed", show.legend = FALSE) +
        geom_point(aes(x = track_name, y = sentiment), size=0.1, show.legend = FALSE) +
        geom_smooth(aes(x = as.numeric(track_number), color=..y..), size = 1, show.legend = FALSE, se = FALSE, span = 0.3) +
        geom_smooth(aes(x = as.numeric(track_number)), color="black", size = 0.2, show.legend = FALSE, alpha = 0.9, se = FALSE, span = 0.3) +
        facet_grid(~album_name, scales = "free", space = "free") +
        scale_color_distiller(type = "div", palette = "RdYlGn", direction = 1, values = c(0,0.5,1)) +
        theme_few(base_family = 'GillSans') +
        theme(axis.text.x=element_text(size = 4, angle = 90, hjust = 1, vjust = 0.2),
              axis.text.y=element_text(size = 5, angle = 90, hjust = 0.5),
              axis.title.x=element_text(size = 9, angle = 180),
              axis.title.y=element_text(size = 9, angle = 90),
              strip.text = element_text(size = 7, angle = 90, vjust = 0)) +
        xlab("") +
        ylab("Lyrical sentiment in Kendrick Lamar's albums") +
        scale_y_continuous(limits = c(-1,1),
                           labels = c("very negative", 
                                      "negative", 
                                      "neutral", 
                                      "positive", 
                                      "very positive"))

# Save and rotate.
ggsave("../results/lyric_sent_plot.png", width = 4, height = 5)
lyric_sent_plot <- image_read('../results/lyric_sent_plot.png')
lyric_sent_plot <- image_rotate(lyric_sent_plot, 90)
image_write(lyric_sent_plot, path = "../results/lyric_sent_plot.png", format = "png")
```

![](../results/lyric_sent_plot.png)

Fans of Kendrick's music will recognize that many of the sentiment scores match expectations. Positive songs like [LOVE. FEAT. ZACARI](https://genius.com/Kendrick-lamar-love-lyrics) and [Poetic Justice](https://genius.com/Kendrick-lamar-poetic-justice-lyrics) have high scores, and negative songs like [FEEL](https://genius.com/Kendrick-lamar-feel-lyrics) and [The Blacker the Berry](https://genius.com/Kendrick-lamar-the-blacker-the-berry-lyrics) have low scores.

But there are some mistakes, too. One of the main weaknesses of this measure of lyrical sentiment is that it can't pick up on negation or irony. For example, the song that was identified as having the second-most positive lyrics in Kendrick's whole discography was [No Make-up (Her Vice)](https://genius.com/Kendrick-lamar-no-makeup-her-vice-lyrics):

<iframe width="560" height="315" src="https://www.youtube.com/embed/xQtWY-ZxFTw" frameborder="0" allowfullscreen></iframe>

Despite its eerie melody and tragic story (revealed in the final line), the song got a high sentiment score because of the many positive words in the chorus:

> I **love** the way you put it on your eyes
> The **roses** on your face **light** up the sky
> Those lips are **colorful** all of the time
> And girl, that's fine, but I wanna know do you mind
> No make-up today, no make-up today

The verses also repeat the words, "beautiful," "beauty," "wonderful blessing," "heaven," and "smile." 

Another problem with this measure of lyrical sentiment is that it always treats profanity as being negative, which isn't always accurate in rap music. And Kendrick is very profane. If you're up for it, you can see a word cloud of his most used words [here](https://github.com/laingdk/kendrick/blob/master/results/kendrick_wordcloud.png).

```{r wordcloud, include = FALSE, echo = FALSE}
png("../results/kendrick_wordcloud.png", width=5, height=5, units="in", res=300)
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Kendrick Lamar's most-used words")
wordcloud <- cleaned_kendrick %>%
        count(word) %>%
        with(wordcloud(word, n, max.words = 100, random.order = F, rot.per=0.05))
dev.off()
```

Still, for the most part lyrical sentiment is capturing the general mood of the lyrics. To get a more complete measure of sentiment, I converted the musical and lyrical sentiment scores to the same scale, then took the average between them. I think the plot below gives the best generalization of musical and lyrical sentiment.

```{r sentiment_viz, fig.width=11, fig.height=5, warning=FALSE, message=FALSE}
# Transform the valence to the same scale as the sentiment.
kendrick <- kendrick %>% mutate(valence = ((valence*2)-1))

# Get a smarter measure of sentiment
kendrick <- kendrick %>% mutate(smart_sentiment = (sentiment + valence)/2)

# Now get a measure of the difference between lyric sentiment and song valence.
# This tells us which songs sound positive but are filled with especially negative
# lyrics, or vice versa.
kendrick <- kendrick %>% mutate(sent_val_dif = abs(sentiment - valence))

# See how the full sentiment changes across the albums.
sentiment_plot <- ggplot(kendrick, aes(x = track_name, y = smart_sentiment, color = smart_sentiment)) +
        geom_hline(aes(yintercept=1, color=1), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=0.5, color=0.5), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=0, color=0), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=-0.5, color=-0.5), linetype="dashed", show.legend = FALSE) +
        geom_hline(aes(yintercept=-1, color=-1), linetype="dashed", show.legend = FALSE) +
        geom_point(aes(x = track_name, y = smart_sentiment), size=0.1, show.legend = FALSE) +
        geom_smooth(aes(x = as.numeric(track_number), color=..y..), size = 1, show.legend = FALSE, se = FALSE, span = 0.3) +
        geom_smooth(aes(x = as.numeric(track_number)), color="black", size = 0.2, show.legend = FALSE, alpha = 0.9, se = FALSE, span = 0.3) +
        facet_grid(~album_name, scales = "free", space = "free") +
        scale_color_distiller(type = "div", palette = "RdYlGn", direction = 1, values = c(0,0.5,1)) +
        theme_few(base_family = 'GillSans') +
        theme(axis.text.x=element_text(size = 4, angle = 90, hjust = 1, vjust = 0.2),
              axis.text.y=element_text(size = 5, angle = 90, hjust = 0.5),
              axis.title.x=element_text(size = 9, angle = 180),
              axis.title.y=element_text(size = 9, angle = 90),
              strip.text = element_text(size = 7, angle = 90, vjust = 0)) +
        xlab("") +
        ylab("General sentiment in Kendrick Lamar's music and lyrics") +
        scale_y_continuous(limits = c(-1,1),
                           labels = c("very negative", 
                                      "negative", 
                                      "neutral", 
                                      "positive", 
                                      "very positive"))

# Save the plot.
ggsave("../results/sentiment_plot.png", width = 4, height = 5)

# Read it back in.
sentiment_plot <- image_read('../results/sentiment_plot.png')

# Rotate it.
sentiment_plot <- image_rotate(sentiment_plot, 90)

# Save it again.
image_write(sentiment_plot, path = "../results/sentiment_plot.png", format = "png")
```

![](../results/sentiment_plot.png)

Now here's where things get interesting. I decided to see which songs had the greatest differences between their musical sentiment (as defined by Spotify's "valence") and my measure of lyrical sentiment. For example, I wanted to know which songs sound happy but have sad lyrics, or vice versa. I was also curious to know which songs had the least differences between musical and lyrical sentiment; these would be the most self-consistent, the least ironic.

```{r sent_val_dif}
# Plot the difference between lyrical sentiment and musical valence.
sent_val_dif_plot <- ggplot(kendrick) +
        geom_col(aes(x = track_name,
                     y = sent_val_dif*sign(valence - sentiment),
                     fill = album_name), 
                 alpha = 0.8,
                 show.legend = FALSE) +
        facet_grid(~album_name, scales = "free", space = "free") +
        theme_few(base_family = 'GillSans') +
        theme(axis.text.x=element_text(size = 4, angle = 90, hjust = 1, vjust = 0.2),
              axis.text.y=element_text(size = 5, angle = 90, hjust = 0.5),
              axis.title.x=element_text(size = 9, angle = 180),
              axis.title.y=element_text(size = 9, angle = 90),
              strip.text = element_text(size = 7, angle = 90, vjust=0)) +
        scale_y_continuous(breaks = c(-1, 0, 1), limits = c(-1.5, 1.5), labels = c("negative music, positive lyrics", "self-consistent", "positive music, negative lyrics")) +
        scale_fill_manual(values = c("purple", "darkblue", "darkgrey", "darkgreen", "red")) +
        ylab("Musical vs. lyrical sentiment across Kendrick Lamar's discography") +
        xlab("")

# Save the plot.
ggsave("../results/sent_val_dif_plot.png", width = 4, height = 5)

# Read it back in.
sent_val_dif_plot <- image_read('../results/sent_val_dif_plot.png')

# Rotate it.
sent_val_dif_plot <- image_rotate(sent_val_dif_plot, 90)

# Save it again.
image_write(sent_val_dif_plot, path = "../results/sent_val_dif_plot.png", format = "png")
```

![](../results/sent_val_dif_plot.png)

No Make-up was identified as being especially inconsistent in its sound and lyrics, as predicted. Another sad song with positive lyrics is [Real](https://genius.com/Kendrick-lamar-real-lyrics), in which Kendrick uses the word "love" 49 times:

<iframe width="560" height="315" src="https://www.youtube.com/embed/DDau48PysuU" frameborder="0" allowfullscreen></iframe>

So, the combined sentiment score successfully reeled in the mistakes made by the lyric sentiment score.

One the right side of the graph, we can see that Blow My High (Members Only) was identified as being the song with the greatest positive difference between musical sentiment and lyrical sentiment. So the combined sentiment score was equally successful in correcting for the mistakes in Spotify's measure of musical valence.

The other thing we can see in the plot above is the songs that are the most self-consistent — the ones with the least differences between musical sentiment and lyrical sentiment. If you're a Kendrick fan and you scan through the songs with the smallest bars, you might notice something interesting: most of them are on the high end for general popularity. Could it be that songs with emotionally consistent lyrics and sounds are more likely to be hits?

I tried plotting the number of pageviews on Genius against the absolute difference between musical and lyrical sentiment.

```{r finale1}
ggplot(kendrick) +
        geom_point(aes(x = sent_val_dif, y = pageviews), alpha = 0.6) +
        theme_few(base_family = 'GillSans') +
        scale_y_continuous(labels = comma) +
        labs(title="Pageviews of Kendrick Lamar's songs on genius.com,\nas predicted by musical/lyrical consistency") +
        ylab("Pageviews on genius.com") +
        xlab("Absolute difference between musical sentiment and lyrical sentiment")
```

This looked like a pretty strong pattern to me, but I realized that I should log-transform the pageviews to get more consistent dispersion.

```{r finale2}
ggplot(kendrick) +
        geom_point(aes(x = sent_val_dif, y = log(pageviews)), alpha = 0.6) +
        geom_smooth(aes(x = sent_val_dif, y = log(pageviews)), alpha = 0.2, method = "lm") +
        theme_few(base_family = 'GillSans') +
        scale_y_continuous(labels = comma) +
        labs(title="Log of pageviews of Kendrick Lamar's songs on genius.com,\nas predicted by musical/lyrical consistency") +
        ylab("Log of pageviews on genius.com") +
        xlab("Absolute difference between musical sentiment and lyrical sentiment")
```

It still looked to me like I had found something, so I tried fitting a linear model to see if there is a statistically significant effect. I controlled for the album, which is important because some of the albums have better reputations than others, which could draw in additional pageviews for a given song, and some albums are older than others, which means those pages have had more time to gather pageviews. For the stats geeks, here are the results of my model:

```{r finale3}
summary(lm(log(pageviews) ~ sent_val_dif + album_name, kendrick))
```
I found that the absolute difference between lyrical sentiment and musical sentiment was predictive of pageviews, even when controlling for the album. I think this is pretty cool. Emotional consistency between sounds and lyrics is predictive of a song's popularity. It would be interesting to see whether this effect persists into the future, as more people discover Kendrick Lamar and analyse the lyrics across his discography.






## Topic Modelling

From the visualizations above, we have some idea of what Kendrick likes to rap about. But we could learn even more if we could peel away the extremely common words that are present in most songs, and find the underlying words that are unique to each song and album.

We'll use something called the Term Frequency-Inverse Document Frequency, of tf-idf. It is comprised of two parts:

- The *term frequency* is the frequency at which a term appears in a given document.
- The *inverse document frequency* is the frequency at which that term appears across all documents. (It's the proportion of documents which contain the word at least once.)

So, tf-idf tells us which words appear frequently in one set of documents but not so much in others. If a word is barely used in any of the documents, then it will have a low tf-idf. Similarly, if a word shows up in *many* of the documents, then it will have a low tf-idf. What counts is whether it shows up consistently in one set of documents but not all the others. Let's take a look at the words with the highest tf-idf for each album.

```{r tfidf, fig.width=10, fig.height=4, message = FALSE}
# Get the word counts for each album.
album_word_counts <- kendrick %>% group_by(album_name) %>% summarise(word_count = sum(song_word_count))

# Get the word counts for each track.
word_counts <- tidy_kendrick %>%
        select(album_name, track_number, track_name, word) %>% 
        anti_join(stop_words) %>%
        count(album_name, track_number, track_name, word, sort = TRUE) %>% 
        ungroup() %>% 
        left_join(album_word_counts)

# Take a look.
head(word_counts) %>% select(album_name, track_name, word, n) %>% knitr::kable()

# Get the tf-idf
album_words <- word_counts %>%
        bind_tf_idf(word, album_name, n)

# Look at the words with the highest tf-idf within good kid, m.A.A.d city.
album_words %>%
        filter(album_name == "good kid, m.A.A.d city") %>%
        select(-word_count) %>%
        arrange(desc(tf_idf)) %>% 
        head() %>% select(album_name, track_name, word, tf_idf) %>% knitr::kable()

# Reset the factor levels according to the tf-idf
plot_albums <- album_words %>%
        arrange(desc(tf_idf)) %>%
        mutate(word = factor(word, levels = rev(unique(word))))

# Plot the words for all the albums.
plot_albums %>% 
        group_by(album_name) %>%
        top_n(5) %>%
        ungroup %>%
        ggplot(aes(word, tf_idf, fill = album_name)) +
        geom_col(show.legend = FALSE, alpha = 0.8) +
        labs(x = NULL,
             y = "Term Frequency-Inverse Document Frequency",
             title = "Representative words across Kendrick Lamar's discography") +
        facet_wrap(~album_name, nrow = 1, scales = "free") +
        scale_fill_manual(values = c("purple", "darkblue", "darkgrey", "darkgreen", "red")) +
        theme_tufte(base_family = "GillSans") +
        theme(axis.text.x = element_text(angle = 90)) +
        coord_flip()
```

Let's use word clouds to see more of the words that are important for each album.

```{r word_clouds, warning = FALSE, message = FALSE}
font <- 1

# Word cloud for Section.80
pal1 <- brewer.pal(6, "Purples")
pal1 <- pal1[-(1:4)]
png("../results/album1.png", width=6, height=3, units="in", res=300)
layout(matrix(c(2, 1), ncol=2), widths =c(3, 3))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Section.80", font = font)
plot_albums[plot_albums$album_name == "Section.80",] %>%
        with(wordcloud(word,
                       tf_idf,
                       max.words = 75,
                       random.order = F,
                       scale = c(3,.5),
                       rot.per = 0.05,
                       color = pal1))
dev.off()

# Word cloud for good kid
pal2 <- brewer.pal(7, "Blues")
pal2 <- pal2[-(1:2)]
png("../results/album2.png", width=6, height=3, units="in", res=300)
layout(matrix(c(2, 1), ncol=2), widths =c(3, 3))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "good kid, m.A.A.d city", font = font)
plot_albums[plot_albums$album_name == "good kid, m.A.A.d city",] %>%
        with(wordcloud(word,
                       tf_idf,
                       max.words = 75,
                       random.order = F,
                       scale = c(3,.5),
                       rot.per = 0.05,
                       color = pal2))
dev.off()

# Word cloud for TPAB
pal3 <- brewer.pal(7, "Greys")
pal3 <- pal3[-(1:2)]
png("../results/album3.png", width=6, height=3, units="in", res=300)
layout(matrix(c(2, 1), ncol=2), widths=c(3, 3))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "To Pimp A Butterfly", font = font)
plot_albums[plot_albums$album_name == "To Pimp A Butterfly",] %>%
        with(wordcloud(word,
                       tf_idf,
                       max.words = 75,
                       random.order = F,
                       scale = c(3,.5),
                       rot.per = 0.05,
                       color = pal3))
dev.off()

# Word cloud for untitled unmastered.
pal4 <- brewer.pal(7, "Greens")
pal4 <- pal4[-(1:2)]
png("../results/album4.png", width=6, height=3, units="in", res=300)
layout(matrix(c(2, 1), ncol=2), widths=c(3, 3))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "untitled unmastered.", font = font)
plot_albums[plot_albums$album_name == "untitled unmastered.",] %>%
        with(wordcloud(word,
                       tf_idf,
                       max.words = 75,
                       random.order = F,
                       scale = c(3,.5),
                       rot.per = 0.05,
                       color = pal4))
dev.off()

# Word cloud for DAMN.
pal5 <- brewer.pal(7, "Reds")
pal5 <- pal5[-(1:2)]
png("../results/album5.png", width=6, height=3, units="in", res=300)
layout(matrix(c(2, 1), ncol=2), widths=c(3, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "DAMN.", font = font)
plot_albums[plot_albums$album_name == "DAMN.",] %>%
        with(wordcloud(word,
                       tf_idf,
                       max.words = 75,
                       random.order = F,
                       scale = c(3,.5),
                       rot.per = 0.05,
                       color = pal5))
dev.off()

# Combine all the word clouds onto a single row.
rl <- lapply(sprintf("../results/album%i.png", 1:5), readPNG)
gl <- lapply(rl, rasterGrob, interpolate=TRUE, width = unit(2,"in"), height=unit(1,"in"))
g <- arrangeGrob(grobs=gl, ncol = 1, padding = unit(0.1, "line"),
                 top=textGrob("Representative Words Across Kendrick Lamar's Discography",
                               gp=gpar(fontsize=5,font=font)))
ggsave(file="../results/album_top_words.png", g, height = unit(5, "in"), width = unit(2.5,"in"))

```
![](../results/album_top_words.png)

## Correlations between Spotify data and Genius data

The fact that we've joined the Spotify data with the Genius data means we have an opportunity to see whether any of the variables from one dataset are correlated with variables from the other. Here are a couple interesting correlations I found:

```{r testing, warning = FALSE, message = FALSE}
# Danceable songs are more likely to have a higher number of pageviews.
ggplot(kendrick) +
        geom_point(aes(x = danceability, y = pageviews), alpha = 0.5) +
        geom_smooth(aes(x = danceability, y = pageviews), method = "lm") +
        labs(title="Danceability vs pageviews") +
        xlab("Danceability") +
        ylab("Pageviews") +
        scale_y_continuous(labels = comma)

summary(lm(pageviews ~ danceability, kendrick))

# ...but danceable songs also have fewer annotations per word.
ggplot(kendrick) +
        geom_point(aes(x = danceability, y = (annotations/song_word_count)), alpha = 0.5) +
        geom_smooth(aes(x = danceability, y = (annotations/song_word_count)), method = "lm") +
        labs(title="Danceability vs annotations per word") +
        xlab("Danceability") +
        ylab("Annotations per word")

summary(lm(I(annotations/song_word_count) ~ danceability, kendrick))

kendrick <- kendrick %>% mutate(plot_label = track_name)

kendrick$plot_label[kendrick$pageviews < 2500000 & kendrick$sent_val_dif < 1] <- NA

ggplot(kendrick) +
        geom_point(aes(x = sent_val_dif, y = log(pageviews)), alpha = 0.6) +
        geom_smooth(aes(x = sent_val_dif, y = log(pageviews)), method = "lm", alpha = 0.1) +
        theme_few(base_family = 'GillSans') +
        scale_y_continuous(labels = comma) +
        labs(title="Pageviews of Kendrick Lamar's songs on genius.com,\nas predicted by musical/lyrical consistency") +
        ylab("Log of pageviews on genius.com") +
        xlab("Absolute difference between musical valence and lyrical sentiment")

summary(lm(log(pageviews) ~ sent_val_dif + album_name, kendrick))
```

This is almost a bit sad: people come to Genius to look for analysis of the danceable Kendrick songs they hear on the radio, but those danceable songs have fewer annotations per word than average.

## References

http://rcharlie.com/2017-02-16-fitteR-happieR/
http://tidytextmining.com/tfidf.html#the-bind_tf_idf-function
https://cran.r-project.org/web/packages/tidytext/vignettes/tf_idf.html
https://cran.r-project.org/web/packages/tidytext/vignettes/topic_modeling.html

## Session Info

```{r sessionInfo}
sessionInfo()
```

